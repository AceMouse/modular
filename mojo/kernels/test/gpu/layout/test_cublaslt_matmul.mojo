# ===----------------------------------------------------------------------=== #
#
# This file is Modular Inc proprietary.
#
# ===----------------------------------------------------------------------=== #
# REQUIRES: H100-GPU
# RUN: %mojo-no-debug %s | FileCheck %s

from gpu.cublas.cublas import check_cublas_error
from gpu.cublas.cublaslt import Context, cublasLtCreate, cublasLtDestroy
from gpu.host import DeviceContext
from layout import Layout
from layout._utils import ManagedLayoutTensor, gpu_free, gpu_managed_alloc
from linalg.gpu_blas import cublasLt_fp8_matmul
from memory import UnsafePointer


# CHECK-LABEL: cublaslt_e4m3_e4m3_f32_64x16x32
# CHECK: 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
# CHECK: 496.0 496.0 496.0 496.0 496.0 496.0 496.0 496.0 496.0 496.0 496.0 496.0 496.0 496.0 496.0 496.0
# CHECK: 992.0 992.0 992.0 992.0 992.0 992.0 992.0 992.0 992.0 992.0 992.0 992.0 992.0 992.0 992.0 992.0
# CHECK: 1488.0 1488.0 1488.0 1488.0 1488.0 1488.0 1488.0 1488.0 1488.0 1488.0 1488.0 1488.0 1488.0 1488.0 1488.0 1488.0
# CHECK: 1984.0 1984.0 1984.0 1984.0 1984.0 1984.0 1984.0 1984.0 1984.0 1984.0 1984.0 1984.0 1984.0 1984.0 1984.0 1984.0
# CHECK: 2480.0 2480.0 2480.0 2480.0 2480.0 2480.0 2480.0 2480.0 2480.0 2480.0 2480.0 2480.0 2480.0 2480.0 2480.0 2480.0
# CHECK: 2976.0 2976.0 2976.0 2976.0 2976.0 2976.0 2976.0 2976.0 2976.0 2976.0 2976.0 2976.0 2976.0 2976.0 2976.0 2976.0
# CHECK: 3472.0 3472.0 3472.0 3472.0 3472.0 3472.0 3472.0 3472.0 3472.0 3472.0 3472.0 3472.0 3472.0 3472.0 3472.0 3472.0
# CHECK: 3968.0 3968.0 3968.0 3968.0 3968.0 3968.0 3968.0 3968.0 3968.0 3968.0 3968.0 3968.0 3968.0 3968.0 3968.0 3968.0
# CHECK: 4464.0 4464.0 4464.0 4464.0 4464.0 4464.0 4464.0 4464.0 4464.0 4464.0 4464.0 4464.0 4464.0 4464.0 4464.0 4464.0
# CHECK: 4960.0 4960.0 4960.0 4960.0 4960.0 4960.0 4960.0 4960.0 4960.0 4960.0 4960.0 4960.0 4960.0 4960.0 4960.0 4960.0
# CHECK: 5456.0 5456.0 5456.0 5456.0 5456.0 5456.0 5456.0 5456.0 5456.0 5456.0 5456.0 5456.0 5456.0 5456.0 5456.0 5456.0
# CHECK: 5952.0 5952.0 5952.0 5952.0 5952.0 5952.0 5952.0 5952.0 5952.0 5952.0 5952.0 5952.0 5952.0 5952.0 5952.0 5952.0
# CHECK: 6448.0 6448.0 6448.0 6448.0 6448.0 6448.0 6448.0 6448.0 6448.0 6448.0 6448.0 6448.0 6448.0 6448.0 6448.0 6448.0
# CHECK: 6944.0 6944.0 6944.0 6944.0 6944.0 6944.0 6944.0 6944.0 6944.0 6944.0 6944.0 6944.0 6944.0 6944.0 6944.0 6944.0
# CHECK: 7440.0 7440.0 7440.0 7440.0 7440.0 7440.0 7440.0 7440.0 7440.0 7440.0 7440.0 7440.0 7440.0 7440.0 7440.0 7440.0
# CHECK: 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0
# CHECK: 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0 7936.0
# CHECK: 8928.0 8928.0 8928.0 8928.0 8928.0 8928.0 8928.0 8928.0 8928.0 8928.0 8928.0 8928.0 8928.0 8928.0 8928.0 8928.0
# CHECK: 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0
# CHECK: 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0
# CHECK: 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0 9920.0
# CHECK: 10912.0 10912.0 10912.0 10912.0 10912.0 10912.0 10912.0 10912.0 10912.0 10912.0 10912.0 10912.0 10912.0 10912.0 10912.0 10912.0
# CHECK: 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0
# CHECK: 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0
# CHECK: 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0 11904.0
# CHECK: 12896.0 12896.0 12896.0 12896.0 12896.0 12896.0 12896.0 12896.0 12896.0 12896.0 12896.0 12896.0 12896.0 12896.0 12896.0 12896.0
# CHECK: 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0
# CHECK: 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0
# CHECK: 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0 13888.0
# CHECK: 14880.0 14880.0 14880.0 14880.0 14880.0 14880.0 14880.0 14880.0 14880.0 14880.0 14880.0 14880.0 14880.0 14880.0 14880.0 14880.0
# CHECK: 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0
# CHECK: 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0
# CHECK: 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0
# CHECK: 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0 15872.0
# CHECK: 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0
# CHECK: 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0
# CHECK: 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0 17856.0
# CHECK: 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0
# CHECK: 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0
# CHECK: 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0
# CHECK: 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0
# CHECK: 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0 19840.0
# CHECK: 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0
# CHECK: 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0
# CHECK: 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0 21824.0
# CHECK: 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0
# CHECK: 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0
# CHECK: 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0
# CHECK: 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0
# CHECK: 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0 23808.0
# CHECK: 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0
# CHECK: 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0
# CHECK: 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0 25792.0
# CHECK: 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0
# CHECK: 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0
# CHECK: 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0
# CHECK: 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0
# CHECK: 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0 27776.0
# CHECK: 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0
# CHECK: 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0
# CHECK: 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0 29760.0
# CHECK: 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0
# CHECK: 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0 31744.0
fn main() raises:
    print("== cublaslt_e4m3_e4m3_f32_64x16x32")
    alias M = 64
    alias N = 16
    alias K = 32
    alias a_dtype = DType.float8e4m3
    alias b_dtype = DType.float8e4m3
    alias d_dtype = DType.float32

    var lt_handle = UnsafePointer[Context]()
    check_cublas_error(cublasLtCreate(UnsafePointer.address_of(lt_handle)))

    with DeviceContext() as ctx:
        var lhs = ManagedLayoutTensor[
            a_dtype,
            Layout.row_major(M, K),
            gpu_managed_alloc,
            gpu_free,
        ]()

        @parameter
        for m in range(M):

            @parameter
            for k in range(K):
                lhs.tensor[m, k] = m

        var rhs = ManagedLayoutTensor[
            b_dtype,
            Layout.col_major(K, N),
            gpu_managed_alloc,
            gpu_free,
        ]()

        @parameter
        for k in range(K):

            @parameter
            for n in range(N):
                rhs.tensor[k, n] = k

        var res = ManagedLayoutTensor[
            d_dtype, Layout.col_major(M, N), gpu_managed_alloc, gpu_free
        ]()

        check_cublas_error(
            cublasLt_fp8_matmul(
                lt_handle,
                ctx,
                lhs,
                rhs,
                res,
            )
        )

        print(res.tensor)

    check_cublas_error(cublasLtDestroy(lt_handle))
