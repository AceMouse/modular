# ===----------------------------------------------------------------------=== #
#
# This file is Modular Inc proprietary.
#
# ===----------------------------------------------------------------------=== #
"""Ops for generating random numbers."""

from __future__ import annotations

import math
from contextvars import ContextVar

import numpy as np
from max.dtype import DType
from max.mlir.dialects import rmo

from .. import dtype_promotion
from ..graph import Graph
from ..type import TensorType
from ..value import TensorValue, TensorValueLike
from .elementwise import erf

SEED = ContextVar[TensorValue]("Seed")
SeedType = TensorType(DType.int64, [])


def _rotate_seed(seed: TensorValue):
    # Let's just get some different random numbers
    # from the initial seed for now.
    return seed + 1


def assert_scalar(value: TensorValueLike):
    if isinstance(value, (np.ndarray, TensorValue)) and value.shape:
        raise ValueError("Expected a scalar value")


def _next_seed():
    try:
        seed = SEED.get()
    except LookupError:
        raise RuntimeError("No seed set! Set with `ops.random.set_seed`.")
    SEED.set(_rotate_seed(seed))
    return seed


def set_seed(seed: TensorValue | int = 0):
    """Sets the seed for random numbers generated in the graph.

    This must be set at least once for each graph using random number utilities.
    - If set to a static value, random numbers generated by the graph will be
        deterministic with each graph execution.
    - To get different random values, expose a `seed` input to your graph
        and call `set_seed` with it.

    Args:
        seed: The seed value to use for future random operations. Each subsequent
            random operation will rotate this seed value automatically.
    """
    assert_scalar(seed)
    seed = dtype_promotion._promote_to_strong(seed, DType.int64)
    if seed.dtype != DType.int64:
        raise TypeError("Seed value must be int64")
    return SEED.set(seed)


def gaussian(
    like: TensorType,
    mean: TensorValueLike = 0.0,
    std: TensorValueLike = 1.0,
) -> TensorValue:
    assert_scalar(mean)
    assert_scalar(std)
    # Check whether we have a seed before we add other constants to the graph.
    seed = _next_seed()
    return Graph.current._add_op(
        rmo.mo_random_normal,
        result=like.to_mlir(),
        shape=TensorValue(like.shape),
        mean=dtype_promotion._promote_to_strong(mean, DType.float32),
        variance=dtype_promotion._promote_to_strong(std, DType.float32),
        seed=seed,
    )[0].tensor


# Alias normal <-> gaussian
normal = gaussian


def uniform(
    like: TensorType,
    range: tuple[TensorValueLike, TensorValueLike] = (0, 1),
) -> TensorValue:
    # Transform the gaussian by its CDF, which yields a uniform distribution.
    #  - Scale the gaussian by 1/sqrt(2) to cancel the sqrt(2) factor in the CDF
    #  - After `erf`, distribution is uniform on (-1, 1)
    symmetric_uniform = erf(gaussian(like, std=1 / math.sqrt(2)))
    unit_uniform = (1 + symmetric_uniform) / 2

    lower, upper = range
    assert_scalar(lower)
    assert_scalar(upper)
    lower = dtype_promotion._promote_to_strong(lower, like.dtype)
    upper = dtype_promotion._promote_to_strong(upper, like.dtype)
    scale = upper - lower
    return scale * unit_uniform + lower
